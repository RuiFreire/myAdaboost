{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39707, 38)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "loans = pd.read_csv('LoanStats3a.csv', skiprows=1, low_memory=False)\n",
    "\n",
    "half_count = len(loans) / 2\n",
    "loans = loans.dropna(thresh=half_count, axis=1)\n",
    "loans = loans.drop(['desc', 'url'],axis=1)\n",
    "\n",
    "colsToDrop = [\"id\", \"member_id\", \"funded_amnt\", \"funded_amnt_inv\", \"grade\", \"sub_grade\", \"emp_title\", \"issue_d\"]\n",
    "    \n",
    "loans = loans.drop(colsToDrop, axis=1)\n",
    "        \n",
    "colsToDrop = [\"zip_code\", \"out_prncp\", \"out_prncp_inv\", \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\"]\n",
    "    \n",
    "loans = loans.drop(colsToDrop, axis=1) \n",
    "\n",
    "colsToDrop = [\"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\"]\n",
    "\n",
    "loans = loans.drop(colsToDrop, axis=1)\n",
    "    \n",
    "loans.loan_status.value_counts()\n",
    "\n",
    "loans = loans[ (loans.loan_status == \"Fully Paid\") | (loans.loan_status == \"Charged Off\") ]\n",
    "\n",
    "mapping_dict = {\n",
    "    \"loan_status\": {\n",
    "        \"Fully Paid\": 0, # NOTA: o classificador myAdaboost aceita qualquer tipo de dados como label\n",
    "        \"Charged Off\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "loans.replace(mapping_dict, inplace=True)\n",
    "\n",
    "drop_columns = []\n",
    "\n",
    "cols = list(loans.columns)\n",
    "\n",
    "for col in cols:\n",
    "    non_null = loans[col].dropna()\n",
    "    unique_non_null = non_null.unique()\n",
    "    if len(unique_non_null) == 1:\n",
    "        drop_columns.append(col)\n",
    "        \n",
    "loans = loans.drop(drop_columns, axis = 1)\n",
    "\n",
    "loans = loans.drop(\"pub_rec_bankruptcies\", axis=1)\n",
    "loans = loans.dropna(subset=[\"title\", \"revol_util\", \"last_credit_pull_d\"])\n",
    "\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "loans.replace(mapping_dict, inplace=True)\n",
    "\n",
    "loans[\"emp_length\"].fillna(0, inplace=True)\n",
    "\n",
    "loans = loans.drop([\"last_credit_pull_d\", \"earliest_cr_line\", \"addr_state\", \"title\"], axis=1)\n",
    "\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].str.rstrip(\"%\").astype(\"float\")\n",
    "\n",
    "\n",
    "cat_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "dummy_df = pd.get_dummies(loans[cat_columns])\n",
    "loans = pd.concat([loans, dummy_df], axis=1)\n",
    "loans = loans.drop(cat_columns, axis=1)\n",
    "\n",
    "loans.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "print(loans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_metrics(predictions, target):\n",
    "    \n",
    "    tn = sum( (predictions == 0) & (target == 0) )\n",
    "    #tn = sum( ~(new_predictions | target) )\n",
    "    #print(\"tn: {}\".format(tn))\n",
    "    \n",
    "    fp = sum( (predictions == 1) & (target == 0) )\n",
    "    #fp = sum( new_predictions & ~target )\n",
    "    #print(\"fp: {}\".format(fp))\n",
    "    #print(\"tn + fp: {}\".format(tn + fp))\n",
    "\n",
    "    tp = sum( (predictions == 1) & (target == 1) )\n",
    "    #tp = sum( new_predictions  & target )\n",
    "    #print(\"tp: {}\".format(tp))\n",
    "    \n",
    "    fn = sum( (predictions == 0) & (target == 1) )\n",
    "    #fn = sum( ~new_predictions & target )\n",
    "    #print(\"fn: {}\".format(fn))\n",
    "    #print(\"tp + fn: {}\".format(tp + fn))\n",
    "\n",
    "    tpr = tp / (tp + fn)\n",
    "    tnr = tn / (tn + fp)\n",
    "    fpr = fp / (fp + tn)\n",
    "    npv = tn / (tn + fn)\n",
    "\n",
    "    #print(\"tpr: {}\".format(tpr))\n",
    "    #print(\"fpr: {}\".format(fpr))\n",
    "    #print(\"accuracy: {}\".format((tp+tn)/(tp+tn+fp+fn)) )\n",
    "    \n",
    "    #precision = tn /(tn + fp)\n",
    "    #recall = tn/(tn + fn)\n",
    "    \n",
    "    precision = tp /(tp + fp)\n",
    "    recall = tp/(tp + fn)\n",
    "    acc = (tp + tn)/(tp + tn + fp +fn)\n",
    "    \n",
    "    F1 = 2*(precision*recall)/(precision + recall)\n",
    "    \n",
    "    return tp, fp, tn, fn, tpr, tnr, fpr, precision, acc, F1, npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "################### My Adaboost Class - Definition\n",
    "##############\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "class myAdaboost(BaseEstimator, ClassifierMixin):  \n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, threshold=0.5, number_of_iterations=50, classifier=None):\n",
    "        \n",
    "        self.threshold = threshold\n",
    "        self.T = number_of_iterations\n",
    "        self.weak_learners_list = []\n",
    "        self.classifier = classifier\n",
    "\n",
    "    def check_y(self, y):\n",
    "        \n",
    "        if type(y) == type(pd.Series([])):\n",
    "            \n",
    "            if pd.isnull(y).sum() > 0:\n",
    "                raise NameError(\"There are None ou Nan values in y\")\n",
    "    \n",
    "            if not ( np.array_equal( y.unique(), np.array([1, 0]) )  or  np.array_equal( y.unique(), np.array([0, 1]) ) ):\n",
    "                raise NameError( \"y must be a pandas Series or an 1d numpy array with numeric binary values: (0,1)\")\n",
    "            \n",
    "            \n",
    "        if type(y) == type(np.array([])):       \n",
    "\n",
    "            if pd.isnull(pd.Series( y ) ).sum() > 0:\n",
    "                raise NameError(\"There are None ou Nan values in y\")\n",
    "            \n",
    "            if y.dtype == \"object\":\n",
    "                raise NameError(\"y is an array of type objcet. y must be a pandas Series or an 1d numpy array with numeric binary values: (0,1) \")\n",
    "            \n",
    "            if not ( np.array_equal(np.unique(y), np.array([0, 1])) or  np.array_equal(np.unique(y), np.array([1, 0])) ):\n",
    "                raise NameError(\"y must be a pandas Series or an 1d numpy array with numeric binary values: (0,1)\")       \n",
    "    \n",
    "    \n",
    "    def fit(self, X=None, y=None):\n",
    "        \n",
    "        \n",
    "        # calling a method to ensure that \"y is a pandas Series or an 1d numpy array with numeric binary values: (0,1)\"\n",
    "        self.check_y(y)\n",
    "        \n",
    "        X_, y_ = check_X_y(X, y)\n",
    "        y_[ y_==0 ] = -1\n",
    "        \n",
    "        weights = np.array( [1/len(y_)]*len(y_) )\n",
    "        \n",
    "        np.random.seed(seed=123)\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            \n",
    "            dic = {}\n",
    "                  \n",
    "            train_set_index = np.random.choice(a=len(y_), size=len(y_), p=weights, replace=True)\n",
    "                 \n",
    "            self.classifier.fit( X_[train_set_index], y_[train_set_index] )\n",
    "            new_predictions = self.classifier.predict( X_ )\n",
    "            \n",
    "            new_error = sum( weights*( new_predictions != y_ ) )\n",
    "        \n",
    "            new_cl = copy.deepcopy( self.classifier )\n",
    "            \n",
    "            alpha = 0.5*np.log( ( 1-new_error )/new_error )\n",
    "        \n",
    "            sys.stdout.write('\\rIteration:' + str(t) + \" | error:\" + str(new_error) + \" | alpha:\" + str(alpha)  )\n",
    "        \n",
    "            dic[\"weak_learner\"] = new_cl\n",
    "            dic[\"alpha\"] = alpha\n",
    "        \n",
    "            preNormWeights = weights * np.exp( -1*dic[\"alpha\"]*(y_*new_predictions) )\n",
    "        \n",
    "            weights = preNormWeights/preNormWeights.sum()\n",
    "            weights = np.array(weights)\n",
    "            \n",
    "            self.weak_learners_list.append(dic)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        sum_predictions = np.matrix( [0.0]*len(X) )\n",
    "        \n",
    "        for weak_learner in self.weak_learners_list:\n",
    "            predictions = weak_learner[\"weak_learner\"].predict( X )\n",
    "            sum_predictions += weak_learner[\"alpha\"]*predictions\n",
    "    \n",
    "        mMscaler = MinMaxScaler()\n",
    "\n",
    "        mMscaler.fit(sum_predictions.T)\n",
    "\n",
    "        sum_predictions_norm = mMscaler.transform(sum_predictions.T)\n",
    "        \n",
    "        sum_predictions_norm = np.concatenate( ( (1-sum_predictions_norm), sum_predictions_norm), axis=1 )\n",
    "        \n",
    "        return np.array(sum_predictions_norm)\n",
    "  \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predictions = self.predict_proba(X)[:,1]\n",
    "        \n",
    "        predictions[ predictions >= self.threshold ] = 1\n",
    "        predictions[ predictions < self.threshold ] = 0\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, X=None, y=None):\n",
    "        \n",
    "        predictions = self.predict(X)\n",
    "        acc = accuracy_score(y, predictions, normalize=True, sample_weight=None)\n",
    "        return  acc\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:49 | error:0.489088061549 | alpha:0.0218273426628\n",
      "\n",
      "\n",
      "[[7294 3961]\n",
      " [ 715 1134]]\n",
      "\n",
      "AUC Score (Test): 0.686664\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "################### My Adaboost Class\n",
    "##############\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "features_cols = list(loans.columns)\n",
    "features_cols.remove(\"loan_status\")\n",
    "features = loans[features_cols].copy(deep=True)\n",
    "target = loans[\"loan_status\"].copy(deep=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=1)\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "thresh = 0.5\n",
    "\n",
    "myAdaB = myAdaboost(threshold = thresh, number_of_iterations=50, classifier = DecisionTreeClassifier(max_depth=1))\n",
    "myAdaB.fit( X_train, y_train )\n",
    "predictions_prob = myAdaB.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "predictions = pd.Series( myAdaB.predict(X_test) )\n",
    "\n",
    "print(confusion_matrix( y_test, predictions) ) \n",
    "\n",
    "print(\"\\nAUC Score (Test): %f\" % metrics.roc_auc_score(y_test, predictions_prob) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13104\n",
      "1052\n"
     ]
    }
   ],
   "source": [
    "print(10203+1052+1639+210)\n",
    "\n",
    "print( sum( (y_test==0) &(predictions==1) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y must be a pandas Series with binary values (0,1) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import check_array\n",
    "\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "#a = np.array([[0, 0, 1, 1],\n",
    "#              [0, 1, 1, 1]])\n",
    "\n",
    "#a = np.array([[\"a\", \"a\", \"a\", \"a\"],\n",
    "#              [\"a\", \"a\", \"a\", \"a\"],\n",
    "#              [\"a\", \"a\", \"a\", \"a\"]])\n",
    "\n",
    "a = np.array([1, 0, 1, 1, 0, 1])\n",
    "#              [0, 1, 1, 0])\n",
    "\n",
    "#a = np.array([\"a\", \"a\", \"a\", \"a\"])\n",
    "\n",
    "#‘multiclass’: y contains more than two discrete values, is not a sequence of sequences, and is 1d or a column vector.\n",
    "#a = np.array([\"a\", \"b\", \"b\", 1.2, \"c\"])\n",
    "\n",
    "def check_y_integrity(y):\n",
    "\n",
    "    if type(y) != type(pd.Series([])):\n",
    "        print( \"y must be a pandas Series with binary values (0,1) \")\n",
    "        return 0\n",
    "    \n",
    "    if pd.isnull(y).sum() > 0:\n",
    "        print(\"there are None ou Nan values in y series\")\n",
    "        return 0\n",
    "    \n",
    "    y_ = y.values\n",
    "    \n",
    "    type_of_target_ =  type_of_target(y_) \n",
    "    print(type_of_target_)\n",
    "\n",
    "    if type_of_target_ == \"multilabel-indicator\":\n",
    "        print( \"y must be a pandas Series with binary values (0,1) \")\n",
    "        return 0\n",
    "\n",
    "    if type_of_target_ == \"continuous\":\n",
    "        print( \"y must be a pandas Series with binary values (0,1) \")\n",
    "        return 0\n",
    "\n",
    "    if type_of_target_ == \"multiclass\":\n",
    "        print( \"y must be a pandas Series with binary values (0,1) \")\n",
    "        return 0\n",
    "\n",
    "    unique_labels_ = unique_labels(y_)\n",
    "\n",
    "    if not np.array_equal( unique_labels_, np.array([0, 1]) ):\n",
    "        print( \"y must be a pandas Series with binary values (0,1) \")\n",
    "        return 0\n",
    "        \n",
    "    y_[ y_ == 0] = -1\n",
    "    \n",
    "    return pd.Serie(y_, index = y.index)\n",
    "        \n",
    "\n",
    "check_y_integrity(a)\n",
    "    \n",
    "#if type_of_target_ != \"binary\" and type_of_target_ != \"multiclass\":\n",
    "    \n",
    "#    print(\"stop\")\n",
    "#    print(type_of_target_)\n",
    "    \n",
    "\n",
    "#print(unique_labels(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hj' 'hj' 'hj' 'hj' 'hj' 5 'hj' 'hj' 'hj' 'hj']\n",
      "(26603,)\n",
      "['hj' '5' 'hj']\n",
      "(3,)\n",
      "<class 'numpy.ndarray'>\n",
      "['5' 'hj']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "y = y_train.values\n",
    "\n",
    "print(y[0:10])\n",
    "print(y.shape)\n",
    "y = np.array([\"hj\", 5, \"hj\"]) \n",
    "print(y)\n",
    "print(y.shape)\n",
    "\n",
    "print(type(y))\n",
    "\n",
    "print(unique_labels(y))\n",
    "\n",
    "#print(type_of_target(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y must be a pandas Series with numeric binary values (0,1) \n"
     ]
    }
   ],
   "source": [
    "if not ( np.array_equal( y_train.unique(), np.array([1, 0]) )  or  np.array_equal( y_train.unique(), np.array([0, 1]) ) ):\n",
    "    print( \"y must be a pandas Series with numeric binary values (0,1) \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['d', 1], dtype=object)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C  D\n",
      "a  b  5  9  4\n",
      "c  2  6  1  6\n",
      "e  3  7  2  8\n",
      "f  4  8  3  1\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-81f8f7262a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'b'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.utils import check_X_y\n",
    "\n",
    "X = pd.DataFrame({'A' : [\"b\", 2, 3, 4],\n",
    "                  'B' : [5, 6, 7, 8],\n",
    "                  'C' : [9, 1, 2, 3],\n",
    "                  'D' : [4, 6, 8, 1] }, index=['a', 'c', 'e', 'f'])\n",
    "\n",
    "y = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "                  \n",
    "print( check_X_y(X, y) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C  D\n",
      "a  1  5  9  4\n",
      "c  2  6  1  6\n",
      "e  3  7  2  8\n",
      "f  4  8  3  1\n",
      "[[ 0.09016696  0.45083482  0.81150267  0.36066785]\n",
      " [ 0.22792115  0.68376346  0.11396058  0.68376346]\n",
      " [ 0.26726124  0.62360956  0.17817416  0.71269665]\n",
      " [ 0.42163702  0.84327404  0.31622777  0.10540926]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X = pd.DataFrame({'A' : [1, 2, 3, 4],\n",
    "                  'B' : [5, 6, 7, 8],\n",
    "                  'C' : [9, 1, 2, 3],\n",
    "                  'D' : [4, 6, 8, 1] }, index=['a', 'c', 'e', 'f'])\n",
    "\n",
    "print(X)\n",
    "\n",
    "y = pd.Series([1, 2, 3, 4])\n",
    "\n",
    "print(normalize(X, norm = \"l2\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5\n"
     ]
    }
   ],
   "source": [
    "print( 2-(1+2+3+4)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5  -1.5   5.25 -0.75]\n",
      " [-0.5  -0.5  -2.75  1.25]\n",
      " [ 0.5   0.5  -1.75  3.25]\n",
      " [ 1.5   1.5  -0.75 -3.75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=False)\n",
    "scaler.fit(X)\n",
    "\n",
    "print(scaler.transform(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [3]\n",
      " [4]]\n",
      "[[-1.33630621]\n",
      " [ 0.26726124]\n",
      " [ 1.06904497]]\n",
      "[[ 0.        ]\n",
      " [ 0.66666667]\n",
      " [ 1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "X = np.matrix([[1, 3, 4]])\n",
    "#X = np.matrix([[1],\n",
    "#               [3], \n",
    "#               [4]])\n",
    "\n",
    "#X = X.reshape(-1, 1) \n",
    "\n",
    "print(X.T)\n",
    "\n",
    "\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "scaler.fit(X.T),\n",
    "X = scaler.transform(X.T)\n",
    "\n",
    "print(X)\n",
    "\n",
    "mMscaler = MinMaxScaler()\n",
    "\n",
    "mMscaler.fit(X)\n",
    "\n",
    "print(mMscaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3]\n",
      " [3 4]\n",
      " [5 5]]\n",
      "[[1 3]\n",
      " [3 4]\n",
      " [5 5]]\n"
     ]
    }
   ],
   "source": [
    "m = np.matrix([[1, 3],\n",
    "               [3, 4],\n",
    "               [5, 5]])\n",
    "\n",
    "print(m)\n",
    "\n",
    "a = np.array(m)\n",
    "\n",
    "type(a)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
